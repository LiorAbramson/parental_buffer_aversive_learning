DROI_mPFC_cond2$contrast <- rep(c("noise_baseline","plus_minus"),times=nrow(valid_subj))
DROI_mPFC_cond2 <- reshape(DROI_mPFC_cond2, timevar="contrast",idvar="Subject", direction="wide")
DROI_mPFC_cond2$order <- "cond2"
#combine conditions
DROI_mPFC <- rbind(DROI_mPFC_cond1,DROI_mPFC_cond2)
#get parental context information
DROI_mPFC <- merge(DROI_mPFC,DParentInfoLong, by=c("Subject","order"), all.x=T, all.y=F)
#merge with sex and age
DROI_mPFC <- merge(DROI_mPFC,DBehav_Wide[,c("Subject","SEX","MRI_AGE")],
by="Subject", all.x=T, all.y=F)
#turn the independent variables to numeric and scale them
DROI_mPFC <- DROI_mPFC %>%
dplyr::mutate(SEX_num = ifelse(SEX=="m",0,1),
SEX_num_c = scale(SEX_num,scale=F),
Parent_Alone_num = ifelse(Parent_Alone=="Alone",0,1),
Parent_Alone_num_c = scale(Parent_Alone_num,scale=F),
MRI_AGE_c = scale(MRI_AGE, scale=F))
#create a wide format for later plotting and visualization purposes
DROI_mPFC_wide <- reshape(DROI_mPFC, timevar="Parent_Alone",idvar="Subject", direction="wide")
#age
describe(DROI_mPFC$MRI_AGE[DROI_mPFC$Parent_Alone=="Parent"]) #choose only one row per subject (doesn't matter which)
#sex
summary(as.factor(DROI_mPFC$SEX[DROI_mPFC$Parent_Alone=="Parent"]))
#look at the descriptive statistics
describeBy (data= DROI_mPFC, mPFC_activation.noise_baseline~Parent_Alone)
#multilevel linear regression- main analysis
lmer_mPFC_noise_baseline<-lmer(data= DROI_mPFC, mPFC_activation.noise_baseline~Parent_Alone_num_c+(1|Subject))
report(lmer_mPFC_noise_baseline)
#analysis controlling for sex and age
lmer_mPFC_noise_baseline_sex_age <- lmer(data=DROI_mPFC, mPFC_activation.noise_baseline~
Parent_Alone_num_c*SEX_num_c +
Parent_Alone_num_c*MRI_AGE_c + (1|Subject))
report(lmer_mPFC_noise_baseline_sex_age)
#look at the descriptive statistics
describeBy (data= DROI_mPFC, mPFC_activation.plus_minus~Parent_Alone)
#multilevel linear regression- main analysis
lmer_mPFC_plus_minus<-lmer(data= DROI_mPFC, mPFC_activation.plus_minus~Parent_Alone_num_c+(1|Subject))
report(lmer_mPFC_plus_minus)
#analysis controlling for sex and age
lmer_mPFC_plus_minus_sex_age <- lmer(data=DROI_mPFC, mPFC_activation.plus_minus~
Parent_Alone_num_c*SEX_num_c +
Parent_Alone_num_c*MRI_AGE_c +(1|Subject))
report(lmer_mPFC_plus_minus_sex_age)
#see how many subjects show decrease and how many show increase according to parental context
DROI_mPFC_wide <- DROI_mPFC_wide %>%
mutate(trend_mPFC_plusmin = ifelse(mPFC_activation.plus_minus.Parent>mPFC_activation.plus_minus.Alone,1,
ifelse(mPFC_activation.plus_minus.Parent<mPFC_activation.plus_minus.Alone,-1,NA))
)
DROI_mPFC <- merge(DROI_mPFC,DROI_mPFC_wide[,c("Subject","trend_mPFC_plusmin")],
by="Subject", all.x=T, all.y=F)
summary(as.factor(DROI_mPFC_wide$trend_mPFC_plusmin))
#visualize results - separate colors for partcipants that showed increase or decrease in parental presence vs absence
plot_mPFC_plusmin <- ggplot(data = DROI_mPFC,
aes(group=interaction(Subject,trend_mPFC_plusmin), x=Parent_Alone,y = mPFC_activation.plus_minus, color=as.factor(trend_mPFC_plusmin)))+
geom_line(aes(group=interaction(Subject,trend_mPFC_plusmin), x=Parent_Alone,y=mPFC_activation.plus_minus, color=as.factor(trend_mPFC_plusmin)), size=1)+
stat_summary(fun=mean,geom="line",lwd=2,color="black",aes(group=1))+
scale_color_brewer(palette="Set2")+
theme_classic() +
labs (x = "", y = "Activation (CS+ vs. CS-)", title="")+
theme(axis.text = element_text(size = 40) , axis.title = element_text(size = 40))+
theme(legend.position="none", plot.title = element_text(hjust = 0.5, size=50))+
scale_x_discrete(expand = expansion(mult=c(0.4,2)), labels=c("absence", "presence"))+
scale_y_continuous(limits = c(-1.2, 1.2), breaks = seq(-1,1,.5))
#contrast 1
DROI_amyg_cond1 <- read.csv ("data/ROI_juelich_thr60_cmamyg_bilateral_resample_NL6Asym_cond1.csv")
DROI_amyg_cond1$Subject <- rep(valid_subj$Subject, each=2)
DROI_amyg_cond1$Subject <- as.numeric(gsub("sub-","",DROI_amyg_cond1$Subject))
DROI_amyg_cond1$contrast <- rep(c("noise_baseline","plus_minus"),times=nrow(valid_subj))
DROI_amyg_cond1 <- reshape(DROI_amyg_cond1, timevar="contrast",idvar="Subject", direction="wide")
DROI_amyg_cond1$order <- "cond1"
#contrast 2
DROI_amyg_cond2 <- read.csv ("data/ROI_juelich_thr60_cmamyg_bilateral_resample_NL6Asym_cond2.csv")
DROI_amyg_cond2$Subject <- rep(valid_subj$Subject, each=2)
DROI_amyg_cond2$Subject <- as.numeric(gsub("sub-","",DROI_amyg_cond2$Subject))
DROI_amyg_cond2$contrast <- rep(c("noise_baseline","plus_minus"),times=nrow(valid_subj))
DROI_amyg_cond2 <- reshape(DROI_amyg_cond2, timevar="contrast",idvar="Subject", direction="wide")
DROI_amyg_cond2$order <- "cond2"
#combine conditions
DROI_amyg <- rbind(DROI_amyg_cond1,DROI_amyg_cond2)
#merge with parent/alone version
DROI_amyg <- merge(DROI_amyg,DParentInfoLong, by=c("Subject","order"), all.x=T, all.y=F)
#merge with sex and age
DROI_amyg <- merge(DROI_amyg,DBehav_Wide[,c("Subject","SEX","MRI_AGE")],
by="Subject", all.x=T, all.y=F)
#turn the independent variables to numeric and scale them
#create age groups- divide the sample according to children (under 11) and adolescents (age cutoff according to gee 2014)
DROI_amyg <- DROI_amyg %>%
dplyr::mutate(SEX_num = ifelse(SEX=="m",0,1),
SEX_num_c = scale(SEX_num,scale=F),
Parent_Alone_num = ifelse(Parent_Alone=="Alone",0,1),
Parent_Alone_num_c = scale(Parent_Alone_num,scale=F),
MRI_AGE_c = scale(MRI_AGE, scale=F))
#create a wide format for later plotting and visualization purposes
DROI_amyg_wide <- reshape(DROI_amyg, timevar="Parent_Alone",idvar="Subject", direction="wide")
DROI_amyg$activ_standard <- scale(DROI_amyg$amyg_activation.noise_baseline, scale=T)
View(DROI_amyg)
describe(DROI_amyg$activ_standard)
lmer_amyg_noise_baseline<-lmer(data= DROI_amyg, activ_standard~Parent_Alone_num_c+(1|Subject))
report(lmer_amyg_noise_baseline)
summary(lmer_amyg_noise_baseline)
-5.780e-01
##################################################################################################
##POWER ANALYSIS_WP1
library(Matrix)
library(lme4)
library(simr)
N <-39
parent_contexts_num <- 2
###simulating the variables
#subject
subject_one <-1:N
subject <- 1:N*parent_contexts_num
subject[subject>0] <-0
for (i in 0:(N-1)) {
subject[(i*4+1):(i*4+4)] <- rep(subject_one[i+1],4)
}
#simulate the subject variable
subject <- rep(1:N, each=parent_contexts_num)
#simulate bold activation variable
activation <- rnorm(n=N*parent_contexts_num, mean=0, sd=1)
#simulate parent context variable
parent_context <- rep(c(0,1),N)
#form one data frame
v<-cbind(subject, activation, parent_context)
v<-as.data.frame(v)
#simulate results with a small effect size
b <- c(0, .2) #intercept, parental context effect
varCor <- .2
s <- .5
model <- makeLmer(activation ~ parent_context +(1|subject),
fixef=b, VarCorr = varCor, sigma=s, data=v)
summary(model)
s <- 1
model <- makeLmer(activation ~ parent_context +(1|subject),
fixef=b, VarCorr = varCor, sigma=s, data=v)
summary(model)
pow<-powerSim(model, nsim=1000)#, test = fcompare(likeRESP~version+time))
s <- .5
model <- makeLmer(activation ~ parent_context +(1|subject),
fixef=b, VarCorr = varCor, sigma=s, data=v)
summary(model)
varCor <- .5
s <- .5
model <- makeLmer(activation ~ parent_context +(1|subject),
fixef=b, VarCorr = varCor, sigma=s, data=v)
summary(model)
#simulate results with a small effect size
b <- c(0, .25) #intercept, parental context effect
varCor <- .5
s <- .5
#simulate results with a small effect size
b <- c(0, .25) #intercept, parental context effect
varCor <- .5
s <- .5
model <- makeLmer(activation ~ parent_context +(1|subject),
fixef=b, VarCorr = varCor, sigma=s, data=v)
summary(model)
model <- makeLmer(activation ~ parent_context +(1|subject),
fixef=b, VarCorr = varCor, sigma=s, data=v)
summary(model)
pow<-powerSim(model, nsim=1000)#, test = fcompare(likeRESP~version+time))
pow
summary(lmer_amyg_noise_baseline)
varCor <- .2
s <- .5
model <- makeLmer(activation ~ parent_context +(1|subject),
fixef=b, VarCorr = varCor, sigma=s, data=v)
summary(model)
pow<-powerSim(model, nsim=1000)#, test = fcompare(likeRESP~version+time))
pow
model <- makeLmer(activation ~ parent_context +(1|subject),
fixef=b, data=v)
model <- makeLmer(activation ~ parent_context +(1|subject),
fixef=b, VarCorr = varCor, data=v)
summary(model)
varCor <- .05
model <- makeLmer(activation ~ parent_context +(1|subject),
fixef=b, VarCorr = varCor, data=v)
summary(model)
varCor <- .003
s <- .5
model <- makeLmer(activation ~ parent_context +(1|subject),
fixef=b, VarCorr = varCor, data=v)
#simulate results with a small effect size
b <- c(0, .25) #intercept, parental context effect
varCor <- .003
s <- .5
model <- makeLmer(activation ~ parent_context +(1|subject),
fixef=b, VarCorr = varCor, data=v)
s <- .5
model <- makeLmer(activation ~ parent_context +(1|subject),
fixef=b, VarCorr = varCor, sigma=s, data=v)
summary(model)
s <- .3
model <- makeLmer(activation ~ parent_context +(1|subject),
fixef=b, VarCorr = varCor, sigma=s, data=v)
summary(model)
pow<-powerSim(model, nsim=1000)
varCor <- .01
s <- .3
model <- makeLmer(activation ~ parent_context +(1|subject),
fixef=b, VarCorr = varCor, sigma=s, data=v)
summary(model)
pow<-powerSim(model, nsim=1000)
s <- .5
model <- makeLmer(activation ~ parent_context +(1|subject),
fixef=b, VarCorr = varCor, sigma=s, data=v)
summary(model)
pow<-powerSim(model, nsim=1000)
install.packages("simr")
rm(list=ls())
##################################################################################################
##POWER ANALYSIS_WP1
library(Matrix)
library(lme4)
library(simr)
N <-150
###simulating the variables
#subject
rounds = 6
clicks=12
subject_one <-1:N
subject <-rep (1:150, each=rounds*clicks)#1:N*rounds*clicks
subject
install.packages("GlmSimulatoR")
?simulate_tweedie
library(GlmSimulatoR)
?simulate_tweedie
simulate_tweedie(
N = length(subject),
link = "log",
weights = 0.02,
xrange = 1,
unrelated = 0,
ancillary = 1.15
)
mindist <- simulate_tweedie(
N = length(subject),
link = "log",
weights = 0.02,
xrange = 1,
unrelated = 0,
ancillary = 1.15
)
12*6*120
hist(mindist)
View(mindist)
hist(mindist$Y)
hist(mindist$Y, breaks=100)
hist(mindist$X1, breaks=100)
summary(mindist$Y)
rm(list=ls())
#cohen D function
cohensd.ci <- function(d, n1, n2, ci = 0.95) {
t <- d * sqrt((n1 * n2)/(n1 + n2))
capture.output(
fit <- compute.es::tes(t = t, n.1 = n1, n.2 = n2, level = 100 * ci),
file = "NUL"
)
c(lower.ci = fit$l.d, upper.ci = fit$u.d)
}
#packages
packages <- c('plyr', 'jsonlite', 'lsr', 'BayesFactor', "compute.es",'gridExtra', 'BayesFactor', 'tidyverse', "RColorBrewer", "lme4", "sjPlot", "lsr", "brms", "kableExtra", 'forcats','coin', 'rstatix','psych','sjstats','reghelper','report','interactions','cplm','ggpubr', 'bayestestR',"parameters", 'glmmTMB')
lapply(packages, require, character.only = TRUE)
set.seed(0815)
# file with various statistical functions (taken from Schulz et al. 2018), among other things it provides tests for Bayes Factors (BFs)
source('statisticalTests.R')
dat <- read.csv(file="../B_data/ATEdata_anonym.csv", stringsAsFactors = T)
dat$id <- as.factor(dat$id)
dat_attach <- read.csv(file="../B_data/ATEdata_attachquiz_anonym_coded.csv")
#Flag participants with problematic data:
#answered in the stranger condition that fits attachment relationships: 248,262,291,301
#this actually the same participant and possibly spam according to prolific- 302,321
#very high outliers in the computational model parameters: 276,320, 329 (see ATE_RBFmodel_analyses.Rmd)
#check which participants didn't move
nomove <- dat[dat$condition=="attachment"| dat$condition=="stranger",] %>%
group_by(id, round) %>%
summarise(move_sum = sum(type_choice!="Repeat", na.rm=T))
nomove <- nomove%>%
mutate(nomove_atall = ifelse(move_sum==0,1,0))
nomove_summary <- nomove%>%
group_by(id) %>%
summarise(nomove_atall_rounds = sum(nomove_atall),
movesum_allrounds = sum(move_sum))
#remove also 209,228,229 because they didn't move at all
subj_prob <- c(209,228,229,248,262,276,291,301,302,320,321, 329)
#for robustness, do the same analyses with the subjects that had extreme model parameters
# subj_prob <- c(209,228,229,248,262,291,301,302,321)
dat$flag <- 0
for (i in 1:length(subj_prob)) { dat$flag[dat$id==subj_prob[i]] <- 1 }
dat <- dat[dat$flag==0,]
#clean dat_attach data
dat_attach$flag <- 0
for (i in 1:length(subj_prob)) { dat_attach$flag[dat_attach$id==subj_prob[i]] <- 1 }
dat_attach <- dat_attach[dat_attach$flag==0,]
#adjust verbal answers
dat_attach$attachq_years[dat_attach$attachq_years=="ans_a few months"] <- "ans_0.4" #approximate to something between 0-0.5 year
dat_attach$attachq_years[dat_attach$attachq_years=="ans_Less than one month"] <- "ans_0.08" #approximate to 1 month
#turn vars to numeric vars
dat_attach$attachq_years <- as.numeric(gsub("ans_","",dat_attach$attachq_years))
dat_attach$attachq_somebad <- as.numeric(gsub("op","",dat_attach$attachq_somebad))
dat_attach$attachq_somegood <- as.numeric(gsub("op","",dat_attach$attachq_somegood))
#how many years do you know the person you chose
describeBy (data= dat_attach, attachq_years ~ condition)
years_Mdif <- mean(subset(dat_attach, condition == "attachment")$attachq_years) - mean(subset(dat_attach, condition == "stranger")$attachq_years)
t.test (data=dat_attach, attachq_years~condition, paired=FALSE)
cohensD(subset(dat_attach,condition=="attachment")$attachq_years,subset(dat_attach,condition=="stranger")$attachq_years)
#how likely would you talk with the person you chose on something good that happened to you?
describeBy (data=dat_attach, attachq_somegood~condition)
somegood_Mdif <- mean(subset(dat_attach, condition == "attachment")$attachq_somegood) - mean(subset(dat_attach, condition == "stranger")$attachq_somegood)
t.test (data=dat_attach, attachq_somegood~condition, paired=FALSE)
cohensD(subset(dat_attach,condition=="attachment")$attachq_somegood,subset(dat_attach,condition=="stranger")$attachq_somegood)
#how likely would you talk with the person you chose on something bad that happened to you?
describeBy (data=dat_attach, attachq_somebad~condition)
somebad_Mdif <- mean(subset(dat_attach, condition == "attachment")$attachq_somebad) - mean(subset(dat_attach, condition == "stranger")$attachq_somebad)
t.test (data=dat_attach, attachq_somebad~condition, paired=FALSE)
cohensD(subset(dat_attach,condition=="attachment")$attachq_somebad,subset(dat_attach,condition=="stranger")$attachq_somebad)
# find out the mean reward per participant (training and bonus round excluded. first click, randomly chosen by computer excluded)
df_mean_reward_subject <- dat %>%
filter(trial != 0 & (condition=="attachment" |condition == "stranger")) %>%
group_by(id, condition) %>%
dplyr::summarise(n=n(),
mean_reward = mean(z),
sd_reward = sd(z))
# some summary stats for obtained mean rewards divided by condition
desc_table <- as.data.frame(matrix(nrow=4, ncol=8))
colnames(desc_table) <- rep(c("Mean(SD)","Median","Minimum","Maximum"),2)
rownames(desc_table) <- c("reward", "bonus round guess error","bonus round guess confidence","serach distance")
reward_desc_attach <- describe(df_mean_reward_subject$mean_reward[df_mean_reward_subject$condition=="attachment"])
desc_table[1,1:4] <- c(paste0(round(reward_desc_attach$mean,2)," (",round(reward_desc_attach$sd,2),")"),
round(reward_desc_attach$median,2),round(reward_desc_attach$min,2),
round(reward_desc_attach$max,2))
reward_desc_strang <- describe(df_mean_reward_subject$mean_reward[df_mean_reward_subject$condition=="stranger"])
desc_table[1,5:8] <- c(paste0(round(reward_desc_strang$mean,2)," (",round(reward_desc_strang$sd,2),")"),
round(reward_desc_strang$median,2),round(reward_desc_strang$min,2),
round(reward_desc_strang$max,2))
#keep dat with first trial (randomly chosen by the computer) and training and bonus rounds in a separate dataset (we will need it later)
dat_alltrials <- dat
#center variables for hlm analysis  and remove first trial and training and bonus rounds from the dataset
dat <- dat[dat$trial!=0 & (dat$condition=="attachment"|dat$condition=="stranger"),]%>%
mutate(trial_c = as.vector(scale(trial, scale=F)),
condition_num = ifelse(condition=="stranger",0,1),
condition_num_c = as.vector(scale(condition_num,scale=F)))
#hlm analysis
hlm_trial_reward <- lmer(data = dat,z~trial_c*condition_num_c + (1|id))
tab_model(hlm_trial_reward,title = "Reward as a function of round progress and relationships priming",
show.std = TRUE, show.stat = TRUE, file = "freq_hlm_reward.doc")
report(hlm_trial_reward)
#region of significance analysis- find out when, along the round, the difference between attachment and stranger priming is significant
sig_region_trial_reward <- johnson_neyman(model=hlm_trial_reward, pred = condition_num_c , modx = trial_c, alpha = .05)
sig_region_trial_reward_low <- as.numeric(sig_region_trial_reward$bounds[1])
#adapt the region of significance to the non-centered variable just for visualization purposes
sig_region_trial_reward_low_nocent <- sig_region_trial_reward_low+6.5
# mean reward per trial, by condition
df_learning_curve <- dat %>%
group_by(id, condition, trial) %>%
dplyr::summarise(n=n(),
mean_reward = mean(z))
#summarize across participants
df_learning_curve_summary <- df_learning_curve %>%
group_by(condition, trial) %>%
dplyr::summarise(n=n(),
reward = mean(mean_reward),
sd_reward = sd(mean_reward),
se_reward = sd_reward / sqrt(n),
lower_ci = reward - qt(1 - (0.05 / 2), n - 1) * se_reward,
upper_ci = reward + qt(1 - (0.05 / 2), n - 1) * se_reward)
#plot reward and trial with region-of-significance
learning_curve_plot <- ggplot(df_learning_curve_summary, aes(x=trial, y=reward, colour=condition)) +
geom_errorbar(aes(ymin=lower_ci, ymax = upper_ci), width = 0, size=0.2, position=position_dodge(width=0.5)) +
#  geom_point(size = 0.7, position=position_dodge(width=0.5)) +
geom_line(size = 1.0) +
geom_vline(xintercept = sig_region_trial_reward_low_nocent, size=.2) +
scale_color_brewer(palette="Set2")+
scale_y_continuous("Mean reward", limits = c(20, 50), breaks = seq(20,50,5)) +
scale_x_continuous("Click number", limits = c(-0.2, 13.2), breaks = seq(1,12,1)) +
ggtitle("") +
theme_classic() +
theme(aspect.ratio = 1,
plot.title = element_text(hjust = 0.5),
legend.title = element_blank(),
legend.position = 'bottom',
legend.background = element_blank(),
legend.key = element_blank(),
legend.key.height = unit(0.3,"cm"),
legend.text =  element_text(colour="black", size=15),
strip.background = element_blank(),
axis.text = element_text(colour = "black",size=15),
axis.text.y = element_text(colour = "black"),
axis.title = element_text(colour = "black",size=30),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank())
#bring back the first trial to the data (we need it to count the distance also from the randomly chosen trial)
dat <- dat_alltrials[dat_alltrials$condition=="attachment"|dat_alltrials$condition=="stranger",]
#compute the minimal distance
dat$min_distance_L2 <- NA
for (id_i in unique(dat$id)){
for (round_i in c(2:7)){
for (trial_i in 1:12) {
obs <- subset(dat, id==id_i & round==round_i &(trial<=trial_i))   #subset the trials that already happened
distance_L2_x_i <- abs(obs$x[trial_i+1]-obs$x)^2
distance_L2_y_i <- abs(obs$y[trial_i+1]-obs$y)^2
distance_L2_i <- sqrt(distance_L2_x_i+distance_L2_y_i)
distance_L2_i <- distance_L2_i[-(trial_i+1)] #remove the last trial (which is the distance of the tile from itself)
dat$min_distance_L2[dat$id==id_i & dat$round==round_i & dat$trial==trial_i] <- min(distance_L2_i) #put the minimum distance in the data file
}}}
#look at the distribution of the minimal distance
hist(dat$min_distance_L2)
hist(dat$min_distance_L2)
summary(dat$min_distance_L2)
##################################################################################################
##POWER ANALYSIS_WP1
library(Matrix)
library(lme4)
library(simr)
N <-150
###simulating the variables
#subject
rounds = 6
clicks=12
subject_one <-1:N
subject <-rep (1:150, each=rounds*clicks)
mindist <- simulate_tweedie(
N = length(subject),
link = "log",
weights = 0.02,
xrange = 1,
unrelated = 0,
ancillary = 1.15
)
summary(mindist$Y)
?simulate_tweedie
mindist <- simulate_tweedie(
N = length(subject),
link = "log",
weights = 0.02,
# xrange = 1,
unrelated = 0,
ancillary = 1.15
)
mindist <- simulate_tweedie(
N = length(subject),
link = "log",
weights = 0.02,
xrange = 1,
unrelated = 0,
ancillary = 1.15
)
mindist <- simulate_tweedie(
N = length(subject),
link = "log",
weights = 5,
xrange = 1,
unrelated = 0,
ancillary = 1.15
)
hist(mindist$Y)
hist(mindist$Y, breaks=100)
hist(mindist$Y, breaks=10000)
summary(mindist$Y)
mindist <- simulate_tweedie(
N = length(subject),
link = "log",
weights = .02,
xrange = 1,
unrelated = 0,
ancillary = 7
)
mindist <- simulate_tweedie(
N = length(subject),
link = "log",
weights = .02,
xrange = 1,
unrelated = 0,
ancillary = 2
)
summary(mindist$Y)
mindist <- simulate_tweedie(
N = length(subject),
link = "log",
weights = .02,
xrange = 1,
unrelated = 0,
ancillary = 1.15
)
summary(mindist$Y)
hist(mindist$Y, breaks=50)
mindist <- mindist$Y
hist(mindist)
sumary(as.factor(mindist))
summary(as.factor(mindist))
summary(as.factor(dat$min_distance_L2))
summary(as.factor(dat$min_distance_L2))
summary(dat$min_distance_L2)
summary(as.factor(dat$min_distance_L2))
#relationship priming
relationship <- rep(c(-0.5,0.5), length(subject)/2)
summary(as.factor(relationship))
click <- rep(1:12,N)
click
click <- click-6.5
summary(click)
#form one data frame
v<-cbind(subject, mindist, relationship, click)
View(v)
#relationship priming
relationship <- rep(c(-0.5,0.5), each = length(subject)/2)
click <- rep(1:12,N)
click <- click-6.5 #center
#form one data frame
v<-cbind(subject, mindist, relationship, click)
summary(as.factor(v$relationship[v$subject<76]))
